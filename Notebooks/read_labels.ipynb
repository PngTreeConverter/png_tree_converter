{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "from pytesseract import pytesseract\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining path to tesseract.exe \n",
    "pytesseract.tesseract_cmd = '/bin/tesseract'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working on the original image (tree + text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '../test_data/Dendrogram.png'\n",
    "gray_image_path = '../test_data/Dendrogram_gray.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(image_path)\n",
    "img = cv2.resize(img, (int(img.shape[0]*2), int(img.shape[1]*2)))\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh1 = cv2.threshold(img, 0, 255, cv2.THRESH_OTSU |\n",
    "                                        cv2.THRESH_BINARY_INV)\n",
    "if thresh1[0,0]<200:\n",
    "    thresh1 = np.where(thresh1>200, 0, 255)\n",
    "# To read the text from an image (e.g. cropped fragment containing the labels), we need to invert white and black --- see below\n",
    "# cv2.imwrite(gray_image_path, thresh1)\n",
    "# text = pytesseract.image_to_string(gray_image_path)\n",
    "# text[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rect_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (12, 12))\n",
    "if thresh1[0,0]>200:\n",
    "    thresh1 = np.where(thresh1>200, 0, 255)\n",
    "\n",
    "dilation = cv2.dilate(thresh1.astype('uint8'), rect_kernel, iterations = 3)\n",
    "cv2.imwrite('../test_data/dilation_image.jpg', dilation)\n",
    "contours, hierarchy = cv2.findContours(dilation, cv2.RETR_EXTERNAL,\n",
    "                                            cv2.CHAIN_APPROX_NONE)\n",
    "boxes = [cv2.boundingRect(cnt) for cnt in contours]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_countours(image, boxes):\n",
    "    for box in boxes:\n",
    "        x, y, w, h = box\n",
    "        \n",
    "        # Draw the bounding box on the text area\n",
    "        rect = cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        \n",
    "        cv2.imwrite('../test_data/rectanglebox.jpg', rect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_boxes_as_images(image, boxes, char_height=35):\n",
    "    boxes_sorted_y = sorted(boxes, key=lambda x: x[1]+x[3], reverse=True) # height\n",
    "    tree_box = boxes_sorted_y.pop()\n",
    "    x, y, w, h = tree_box\n",
    "    cropped = image[y:y + h, x:x + w]\n",
    "    cv2.imwrite('../test_data/only_tree.png', cropped)\n",
    "    \n",
    "    boxes_labels_sorted_x = sorted(boxes_sorted_y, key=lambda x: x[0]+x[2], reverse=False) # left to right\n",
    "    for b_idx, box in enumerate(boxes_labels_sorted_x):\n",
    "        x, y, w, h = box\n",
    "        cropped = image[y:y + h, x:x + w]\n",
    "        cropped = cv2.resize(cropped, (int(cropped.shape[0]*char_height/cropped.shape[1]), char_height))\n",
    "        cv2.imwrite(f'../test_data/{b_idx}.png', cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "im2 = img.copy()\n",
    "save_boxes_as_images(im2, boxes)\n",
    "draw_countours(im2, boxes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try find a box size which allows us read the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for h in range(60, 80, 2):\n",
    "    im2 = img.copy()\n",
    "    save_boxes_as_images(im2, boxes, char_height=h)\n",
    "    for b_idx in range(len(boxes)-1):\n",
    "        box_path = f'../test_data/{b_idx}.png'\n",
    "        gray_box_path = f'../test_data/{b_idx}_gray.png'\n",
    "        text = pytesseract.image_to_string(box_path)\n",
    "        if any([s in text for s in 'ABCDEFGHI']):\n",
    "            print(text)\n",
    "            print(h)\n",
    "        # let's try make it gray again and - if necessary - reverse the colors\n",
    "        img_b = cv2.imread(box_path)\n",
    "        img_b = cv2.cvtColor(img_b, cv2.COLOR_BGR2GRAY)\n",
    "        ret, thresh1 = cv2.threshold(img_b, 0, 255, cv2.THRESH_OTSU |\n",
    "                                                cv2.THRESH_BINARY_INV)\n",
    "        if thresh1[0,0]>200:\n",
    "            thresh1 = np.where(thresh1>200, 0, 255)\n",
    "        cv2.imwrite(gray_box_path, thresh1)\n",
    "        text = pytesseract.image_to_string(gray_box_path)\n",
    "        if any([s in text for s in 'ABCDEFGHI']):\n",
    "            print(text)\n",
    "            print(h)\n",
    "draw_countours(im2, boxes)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually cropped fragment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '../test_data/Dendrogram_only_text.png'\n",
    "gray_image_path = '../test_data/Dendrogram_only_text_gray.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ABC DEF GH I'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(image_path)\n",
    "img = cv2.resize(img, (300, 75))\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh1 = cv2.threshold(img, 0, 255, cv2.THRESH_OTSU |\n",
    "                                        cv2.THRESH_BINARY_INV)\n",
    "if thresh1[0,0]<200:\n",
    "    thresh1 = np.where(thresh1>200, 0, 255)\n",
    "cv2.imwrite(gray_image_path, thresh1)\n",
    "text = pytesseract.image_to_string(gray_image_path)\n",
    "text[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
